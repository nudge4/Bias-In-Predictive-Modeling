{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats.mstats import gmean\n",
    "import math\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "font = {'size': 24}\n",
    "matplotlib.rc('font', **font)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.read_stata(\"../degree_completion_1/df_new.dta\")\n",
    "predictors = pickle.load(open(\"../degree_completion_1/predictors.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "program = pd.read_csv(\"../degree_completion_6/college_program_race.csv\")\n",
    "program = program.loc[:,['vccsid', 'college']]\n",
    "df_new = program.merge(df_new, on=['vccsid'], how='right')\n",
    "\n",
    "train_df_all = df_new[df_new.valid == 0]\n",
    "test_df_all = df_new[df_new.valid == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J._Sargeant_Reynolds\n",
      "(23333, 355) (4248, 355)\n",
      "Random Forest:\n",
      "Validation AUC = 0.8997\n",
      "Training AUC = 0.9359\n",
      "4248 4248 4248\n",
      "John_Tyler\n",
      "(13918, 355) (2839, 355)\n",
      "Random Forest:\n",
      "Validation AUC = 0.8864\n",
      "Training AUC = 0.9456\n",
      "2839 2839 2839\n",
      "Northern_Virginia\n",
      "(84954, 355) (18246, 355)\n",
      "Random Forest:\n",
      "Validation AUC = 0.8955\n",
      "Training AUC = 0.9316\n",
      "18246 18246 18246\n",
      "Tidewater\n",
      "(59596, 355) (11489, 355)\n",
      "Random Forest:\n",
      "Validation AUC = 0.8712\n",
      "Training AUC = 0.9163\n",
      "11489 11489 11489\n",
      "Thomas_Nelson\n",
      "(20788, 355) (4120, 355)\n",
      "Random Forest:\n",
      "Validation AUC = 0.8609\n",
      "Training AUC = 0.9169\n",
      "4120 4120 4120\n"
     ]
    }
   ],
   "source": [
    "params_dict = {'JSRCC': [12, 120, 10],\n",
    "               'JTCC': [12, 120, 8],\n",
    "               'NVCC': [14, 120, 10],\n",
    "               'TCC': [13, 120, 13],\n",
    "               'TNCC': [12, 160, 9]}\n",
    "cname = {'Northern_Virginia': \"NVCC\", \"Tidewater\": \"TCC\", \"J._Sargeant_Reynolds\": \"JSRCC\", \"Thomas_Nelson\": \"TNCC\", \"John_Tyler\": \"JTCC\"}\n",
    "for r2 in ['J._Sargeant_Reynolds', 'John_Tyler', 'Northern_Virginia', 'Tidewater', 'Thomas_Nelson']:\n",
    "\n",
    "    # Load the training/validation sample\n",
    "    print(r2)\n",
    "    r = cname[r2]\n",
    "    train_df = train_df_all[train_df_all.college == r2]\n",
    "    test_df = test_df_all[test_df_all.college == r2]\n",
    "    print(train_df.shape,test_df.shape)\n",
    "\n",
    "    train_df.loc[:,['vccsid']].to_stata(\"train_id_{}.dta\".format(r), write_index=False)\n",
    "    test_df.loc[:,['vccsid']].to_stata(\"test_id_{}.dta\".format(r), write_index=False)\n",
    "\n",
    "    optimal_d = params_dict[r][0]\n",
    "    optimal_n = params_dict[r][1]\n",
    "    optimal_nf = params_dict[r][2]\n",
    "    rf = RandomForestClassifier(n_estimators=optimal_n, criterion=\"entropy\",\n",
    "                                max_depth=optimal_d,\n",
    "                                random_state=0, n_jobs=-1, max_features=optimal_nf,\n",
    "                                class_weight = calc_cw(train_df.grad_6years))\n",
    "    rf.fit(train_df.loc[:,predictors], train_df.grad_6years)\n",
    "    \n",
    "    # Coefficients and predicted scores\n",
    "    y_test_pred_rf = rf.predict_proba(test_df.loc[:,predictors])[:,1]\n",
    "    y_train_pred_rf = rf.predict_proba(train_df.loc[:,predictors])[:,1]\n",
    "    pickle.dump(y_test_pred_rf, open(\"y_test_pred_rf_{}.p\".format(r), \"wb\"))\n",
    "    pickle.dump(list(test_df.grad_6years), open( \"y_test_{}.p\".format(r), \"wb\"))\n",
    "    pickle.dump(y_train_pred_rf, open(\"y_train_pred_rf_{}.p\".format(r), \"wb\"))\n",
    "    pickle.dump(list(train_df.grad_6years), open(\"y_train_{}.p\".format(r), \"wb\"))\n",
    "    print(\"Random Forest:\")\n",
    "    print(\"Validation AUC = {}\".format(round(roc_auc_score(test_df.grad_6years, y_test_pred_rf),4)))\n",
    "    print(\"Training AUC = {}\".format(round(roc_auc_score(train_df.grad_6years, y_train_pred_rf),4)))\n",
    "    \n",
    "    race_column = []\n",
    "    for i in range(test_df.shape[0]):\n",
    "        if test_df.white.iloc[i] == 1:\n",
    "            race_column.append(\"white\")\n",
    "        elif test_df.afam.iloc[i] == 1:\n",
    "            race_column.append(\"afam\")\n",
    "        elif test_df.hisp.iloc[i] == 1:\n",
    "            race_column.append(\"hisp\")\n",
    "        elif test_df.asian.iloc[i] == 1:\n",
    "            race_column.append(\"asian\")\n",
    "        elif test_df.other.iloc[i] == 1:\n",
    "            race_column.append(\"other\")\n",
    "        else:\n",
    "            race_column.append(\"mi\")\n",
    "    race_column = np.array(race_column)\n",
    "    pred_y = np.array(y_test_pred_rf)\n",
    "    test_y = np.array(test_df.grad_6years)\n",
    "    pred_y = pred_y[race_column != \"mi\"]\n",
    "    test_y = test_y[race_column != \"mi\"]\n",
    "    race_column = race_column[race_column != \"mi\"]\n",
    "    print(len(race_column), len(pred_y), len(test_y))\n",
    "\n",
    "    pred_score_by_race = pd.DataFrame({'race_column': race_column, 'pred_y': pred_y, 'test_y': test_y})\n",
    "    pred_score_by_race.to_csv(\"pred_score_by_race_{}.csv\".format(r), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
