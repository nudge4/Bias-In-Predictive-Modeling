{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_side_z_test(n1, p1, n2, p2):\n",
    "    z = (p2-p1)/np.sqrt(p2*(1-p2)/(n2-1)+p1*(1-p1)/(n1-1))\n",
    "    return 2*(1-stats.norm.cdf(np.abs(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def std_new(p,n):\n",
    "    return np.sqrt(p*(1-p)/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in ['213', '697', '699', '880', '882']:\n",
    "#     df = pd.read_csv(\"pred_score_by_race_{}.csv\".format(c))\n",
    "#     new_pred_real = pd.DataFrame({'pred_y': list(df.pred_y),'real_y': list(df.test_y), 'race': list(df.race_column)})\n",
    "#     new_pred_real.loc[:,'pred_y_binned'] = pd.cut(new_pred_real.pred_y, bins=[0] + list(np.percentile(new_pred_real.pred_y, np.arange(2,100,2))) + [1])\n",
    "#     new_pred_real.loc[:,'pred_y_binned_2'] = pd.cut(new_pred_real.pred_y, bins=[0] + list(np.percentile(new_pred_real.pred_y, np.arange(10,100,10))) + [1])\n",
    "#     white_df = new_pred_real[new_pred_real.race == \"white\"]\n",
    "#     white_df = white_df.iloc[np.argsort(white_df.pred_y), :]\n",
    "#     afam_df = new_pred_real[new_pred_real.race == \"afam\"]\n",
    "#     afam_df = afam_df.iloc[np.argsort(afam_df.pred_y), :]\n",
    "#     print(c, white_df.shape[0], afam_df.shape[0])\n",
    "#     results = []\n",
    "#     for qq in [0.1, 0.2, 0.25, 0.3, 0.33, 0.4, 0.5, 0.6, 0.67, 0.7, 0.75, 0.8, 0.9]:\n",
    "#         print(\"qq = {}\".format(qq))\n",
    "#         q = np.quantile(new_pred_real.pred_y, qq)\n",
    "#         new_pred_real_pct = new_pred_real[new_pred_real.pred_y < q]\n",
    "#         new_pred_real_pct = new_pred_real_pct[new_pred_real_pct.race.apply(lambda x: x in {'white', 'afam'})]\n",
    "#         new_pred_real_pct_agg = new_pred_real_pct.groupby(['race']).agg({'real_y': 'mean', 'pred_y': 'count'}).sort_index().loc[:,['real_y', 'pred_y']]\n",
    "#         n1, p1 = new_pred_real_pct_agg.iloc[0,1], new_pred_real_pct_agg.iloc[0,0]\n",
    "#         n2, p2 = new_pred_real_pct_agg.iloc[1,1], new_pred_real_pct_agg.iloc[1,0]\n",
    "#         p_value_1 = two_side_z_test(n1, p1, n2, p2)\n",
    "#         ratio_1 = n1 / n2\n",
    "#         pp1, pp2 = 0, 1\n",
    "#         j = 1\n",
    "#         # while p_value < 0.05:\n",
    "#         while pp1 < pp2 and j < n2 and n1 + j <= afam_df.shape[0]:\n",
    "#             j += 1\n",
    "#             white_df_new = white_df.iloc[0:(n2-j),:]\n",
    "#             afam_df_new = afam_df.iloc[0:(n1+j),:]\n",
    "#             merged_new = pd.concat([white_df_new, afam_df_new])\n",
    "#             merged_new_agg = merged_new.groupby(['race']).agg({'real_y': 'mean', 'pred_y': 'count'}).sort_index().loc[:,['real_y', 'pred_y']]\n",
    "#             nn1, pp1 = merged_new_agg.iloc[0,1], merged_new_agg.iloc[0,0]\n",
    "#             nn2, pp2 = merged_new_agg.iloc[1,1], merged_new_agg.iloc[1,0]\n",
    "#         p_value_2 = two_side_z_test(nn1, pp1, nn2, pp2)\n",
    "#         ratio_2 = nn1/nn2\n",
    "#         results.append((int(qq*100), p1, p2, n1, n2, pp1, pp2, nn1, nn2, nn1 - n1))\n",
    "#     results_df = \\\n",
    "#     pd.DataFrame(results, columns=[\"bottom_%\", \"success_rate_black\", \"success_rate_white\", \"n1\", \"n2\",\n",
    "#                                    \"success_rate_black\", \"success_rate_white\", \"nn1\",\"nn2\",\n",
    "#                                    \"black_increased\"]).sort_values([\"bottom_%\"]).round(4)\n",
    "#     results_df.to_csv(\"calibration_bias_{}.csv\".format(c), index=False)\n",
    "#     results = []\n",
    "#     for qq in [0.1, 0.2, 0.25, 0.3, 0.33, 0.4, 0.5, 0.6, 0.67, 0.7, 0.75, 0.8, 0.9]:\n",
    "#         print(\"qq = {}\".format(qq))\n",
    "#         q = np.quantile(new_pred_real.pred_y, qq)\n",
    "#         new_pred_real_pct = new_pred_real[new_pred_real.pred_y < q]\n",
    "#         new_pred_real_pct = new_pred_real_pct[new_pred_real_pct.race.apply(lambda x: x in {'white', 'afam'})]\n",
    "#         new_pred_real_pct_agg = new_pred_real_pct.groupby(['race']).agg({'real_y': 'mean', 'pred_y': 'count'}).sort_index().loc[:,['real_y', 'pred_y']]\n",
    "#         n1, p1 = new_pred_real_pct_agg.iloc[0,1], 1 - new_pred_real_pct_agg.iloc[0,0]\n",
    "#         n2, p2 = new_pred_real_pct_agg.iloc[1,1], 1 - new_pred_real_pct_agg.iloc[1,0]\n",
    "#         std1 = std_new(p1, n1)\n",
    "#         std2 = std_new(p2, n2)\n",
    "#         white = new_pred_real[np.array(new_pred_real.race == \"white\") & np.array(new_pred_real.real_y == 0)]\n",
    "#         afam = new_pred_real[np.array(new_pred_real.race == \"afam\") & np.array(new_pred_real.real_y == 0)]\n",
    "#         n3 = white.shape[0]\n",
    "#         n4 = afam.shape[0]\n",
    "#         p3 = np.mean(white.pred_y < q)\n",
    "#         p4 = np.mean(afam.pred_y < q)\n",
    "#         std3 = std_new(p3, n3)\n",
    "#         std4 = std_new(p4, n4)\n",
    "#         results.append((qq, p1, std1, p2, std2, p3, std3, p4, std4))\n",
    "#     results_df = \\\n",
    "#     pd.DataFrame(results, columns=[\"bottom_%\", \n",
    "#                                    \"black\", \"std_black\",\n",
    "#                                    \"white\", \"std_white\",\n",
    "#                                    \"black\", \"std_black\",\n",
    "#                                    \"white\", \"std_white\"]).sort_values([\"bottom_%\"]).round(4)\n",
    "#     results_df.to_csv(\"tnr_precision0_bias_{}.csv\".format(c), index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for r in ['699', '213', '697', '882', '880']:\n",
    "    t1 = pd.read_csv(\"calibration_bias_{}.csv\".format(r))\n",
    "    t2 = pd.read_csv(\"full/calibration_bias_{}.csv\".format(r))\n",
    "    d1 = t1.black_increased.apply(lambda x: 0 if x == 2 else x)\n",
    "    r1 = d1/t1.n1\n",
    "    d2 = t2.black_increased.apply(lambda x: 0 if x == 2 else x)\n",
    "    r2 = d2/t2.n1\n",
    "    l.append(r2)\n",
    "    l.append(r1)\n",
    "pd.DataFrame(np.array(l).T, columns=[e1+e2 for e1 in ['699', '213', '697', '882', '880'] for e2 in ['_1', '_2']]).to_csv(\"calibration_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
