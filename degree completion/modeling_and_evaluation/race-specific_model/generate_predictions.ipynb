{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats.mstats import gmean\n",
    "import math\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "font = {'size': 24}\n",
    "matplotlib.rc('font', **font)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.read_stata(\"../degree_completion_1/df_new.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = pickle.load(open(\"../degree_completion_1/predictors.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_all = df_new[df_new.valid == 0]\n",
    "test_df_all = df_new[df_new.valid == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white\n",
      "(179919, 354) (32288, 354)\n",
      "afam\n",
      "(82784, 354) (16796, 354)\n",
      "hisp\n",
      "(25338, 354) (6370, 354)\n",
      "asian\n",
      "(18395, 354) (3625, 354)\n",
      "other\n",
      "(9690, 354) (2970, 354)\n"
     ]
    }
   ],
   "source": [
    "params_dict = {'white': [16, 140, 10],\n",
    "               'afam': [15, 120, 11],\n",
    "               'hisp': [13, 160, 10],\n",
    "               'asian': [11,100,12],\n",
    "               'other': [13,140,6]}\n",
    "\n",
    "for r in ['white', 'afam', 'hisp', 'asian', 'other']:\n",
    "\n",
    "    # Load the training/validation sample\n",
    "    print(r)\n",
    "    train_df = train_df_all[train_df_all[r] == 1]\n",
    "    test_df = test_df_all[test_df_all[r] == 1]\n",
    "    train_df.loc[:,['vccsid']].to_stata(\"train_id_{}.dta\".format(r), write_index=False)\n",
    "    test_df.loc[:,['vccsid']].to_stata(\"test_id_{}.dta\".format(r), write_index=False)\n",
    "    print(train_df.shape,test_df.shape)\n",
    "\n",
    "    optimal_d = params_dict[r][0]\n",
    "    optimal_n = params_dict[r][1]\n",
    "    optimal_nf = params_dict[r][2]\n",
    "    rf = RandomForestClassifier(n_estimators=optimal_n, criterion=\"entropy\",\n",
    "                                max_depth=optimal_d,\n",
    "                                random_state=0, n_jobs=-1, max_features=optimal_nf,\n",
    "                                class_weight = calc_cw(train_df.grad_6years))\n",
    "    rf.fit(train_df.loc[:,predictors], train_df.grad_6years)\n",
    "    \n",
    "    xx = np.array(predictors)[np.argsort(rf.feature_importances_)[::-1]]\n",
    "    yy = rf.feature_importances_[np.argsort(rf.feature_importances_)[::-1]]\n",
    "    pd.DataFrame({'predictor':xx, 'fi':yy}).to_csv(\"fi_{}.csv\".format(r), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white\n",
      "(179919, 354) (32288, 354)\n",
      "Random Forest:\n",
      "Validation AUC = 0.8984\n",
      "Training AUC = 0.9354\n",
      "afam\n",
      "(82784, 354) (16796, 354)\n",
      "Random Forest:\n",
      "Validation AUC = 0.8834\n",
      "Training AUC = 0.9314\n",
      "hisp\n",
      "(25338, 354) (6370, 354)\n",
      "Random Forest:\n",
      "Validation AUC = 0.8937\n",
      "Training AUC = 0.9415\n",
      "asian\n",
      "(18395, 354) (3625, 354)\n",
      "Random Forest:\n",
      "Validation AUC = 0.8821\n",
      "Training AUC = 0.9378\n",
      "other\n",
      "(9690, 354) (2970, 354)\n",
      "Random Forest:\n",
      "Validation AUC = 0.8852\n",
      "Training AUC = 0.9499\n"
     ]
    }
   ],
   "source": [
    "params_dict = {'white': [16, 140, 10],\n",
    "               'afam': [15, 120, 11],\n",
    "               'hisp': [13, 160, 10],\n",
    "               'asian': [11,100,12],\n",
    "               'other': [13,140,6]}\n",
    "for r in ['white', 'afam', 'hisp', 'asian', 'other']:\n",
    "\n",
    "    # Load the training/validation sample\n",
    "    print(r)\n",
    "    train_df = train_df_all[train_df_all[r] == 1]\n",
    "    test_df = test_df_all[test_df_all[r] == 1]\n",
    "    print(train_df.shape,test_df.shape)\n",
    "\n",
    "    optimal_d = params_dict[r][0]\n",
    "    optimal_n = params_dict[r][1]\n",
    "    optimal_nf = params_dict[r][2]\n",
    "    rf = RandomForestClassifier(n_estimators=optimal_n, criterion=\"entropy\",\n",
    "                                max_depth=optimal_d,\n",
    "                                random_state=0, n_jobs=-1, max_features=optimal_nf,\n",
    "                                class_weight = calc_cw(train_df.grad_6years))\n",
    "    rf.fit(train_df.loc[:,predictors], train_df.grad_6years)\n",
    "    \n",
    "    # Coefficients and predicted scores\n",
    "    y_test_pred_rf = rf.predict_proba(test_df.loc[:,predictors])[:,1]\n",
    "    y_train_pred_rf = rf.predict_proba(train_df.loc[:,predictors])[:,1]\n",
    "    pickle.dump(y_test_pred_rf, open(\"y_test_pred_rf_{}.p\".format(r), \"wb\"))\n",
    "    pickle.dump(list(test_df.grad_6years), open( \"y_test_{}.p\".format(r), \"wb\"))\n",
    "    pickle.dump(y_train_pred_rf, open(\"y_train_pred_rf_{}.p\".format(r), \"wb\"))\n",
    "    pickle.dump(list(train_df.grad_6years), open(\"y_train_{}.p\".format(r), \"wb\"))\n",
    "    print(\"Random Forest:\")\n",
    "    print(\"Validation AUC = {}\".format(round(roc_auc_score(test_df.grad_6years, y_test_pred_rf),4)))\n",
    "    print(\"Training AUC = {}\".format(round(roc_auc_score(train_df.grad_6years, y_train_pred_rf),4)))\n",
    "\n",
    "    pred_score_by_race = pd.DataFrame({'race_column': [r]*test_df.shape[0], 'pred_y': list(y_test_pred_rf), 'test_y': list(test_df.grad_6years)})\n",
    "    pred_score_by_race.to_csv(\"pred_score_by_race_{}.csv\".format(r), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for r in ['white', 'afam', 'hisp', 'asian', 'other']:\n",
    "    df_list.append(pd.read_csv(\"pred_score_by_race_{}.csv\".format(r)))\n",
    "final = pd.concat(df_list)\n",
    "final.to_csv(\"pred_score_by_race.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
