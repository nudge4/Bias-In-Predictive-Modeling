{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script computes the feature importance of predictors and perform comparison of top 10 predictors from different model variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats.mstats import gmean\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.read_stata(\"df_new.dta\")\n",
    "predictors = pickle.load(open(\"predictors.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = df_new[df_new.valid == 0]\n",
    "test_df = df_new[df_new.valid == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True,\n",
       "            class_weight={0.0: 1.0, 1.0: 1.3931639}, criterion='entropy',\n",
       "            max_depth=16, max_features=12, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=120, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_d = 16\n",
    "optimal_n = 120\n",
    "optimal_nf = 12\n",
    "rf = RandomForestClassifier(n_estimators=optimal_n, criterion=\"entropy\",\n",
    "                            max_depth=optimal_d,\n",
    "                            random_state=0, n_jobs=-1, max_features=optimal_nf,\n",
    "                            class_weight = calc_cw(train_df.grad_6years))\n",
    "rf.fit(train_df.loc[:,predictors], train_df.grad_6years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx = np.array(predictors)[np.argsort(rf.feature_importances_)[::-1]]\n",
    "yy = rf.feature_importances_[np.argsort(rf.feature_importances_)[::-1]]\n",
    "fi_base = pd.DataFrame({'predictor':xx, 'fi_base':yy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_afam = train_df[train_df.afam == 1]\n",
    "test_df_afam = test_df[test_df.afam == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True,\n",
       "            class_weight={0.0: 1.0, 1.0: 1.3931639}, criterion='entropy',\n",
       "            max_depth=15, max_features=11, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=120, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_d = 15\n",
    "optimal_n = 120\n",
    "optimal_nf = 11\n",
    "rf_afam = RandomForestClassifier(n_estimators=optimal_n, criterion=\"entropy\",\n",
    "                            max_depth=optimal_d,\n",
    "                            random_state=0, n_jobs=-1, max_features=optimal_nf,\n",
    "                            class_weight = calc_cw(train_df.grad_6years))\n",
    "rf_afam.fit(train_df_afam.loc[:,predictors], train_df_afam.grad_6years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx = np.array(predictors)[np.argsort(rf_afam.feature_importances_)[::-1]]\n",
    "yy = rf_afam.feature_importances_[np.argsort(rf_afam.feature_importances_)[::-1]]\n",
    "fi_afam = pd.DataFrame({'predictor':xx, 'fi_afam':yy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_white = train_df[train_df.white == 1]\n",
    "test_df_white = test_df[test_df.white == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True,\n",
       "            class_weight={0.0: 1.0, 1.0: 1.3931639}, criterion='entropy',\n",
       "            max_depth=15, max_features=11, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=120, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_d = 15\n",
    "optimal_n = 120\n",
    "optimal_nf = 11\n",
    "rf_white = RandomForestClassifier(n_estimators=optimal_n, criterion=\"entropy\",\n",
    "                            max_depth=optimal_d,\n",
    "                            random_state=0, n_jobs=-1, max_features=optimal_nf,\n",
    "                            class_weight = calc_cw(train_df.grad_6years))\n",
    "rf_white.fit(train_df_white.loc[:,predictors], train_df_white.grad_6years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx = np.array(predictors)[np.argsort(rf_white.feature_importances_)[::-1]]\n",
    "yy = rf_white.feature_importances_[np.argsort(rf_white.feature_importances_)[::-1]]\n",
    "fi_white = pd.DataFrame({'predictor':xx, 'fi_white':yy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_all = fi_base.merge(fi_afam, on=['predictor'], how='inner').merge(fi_white, on=['predictor'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "for p in ['fi_base', 'fi_afam', 'fi_white']:\n",
    "    fi_all.loc[:, p+\"_rank\"] = rankdata(fi_all[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025446081110612133 0.014417848999630981\n",
      "1.1319429450539957 0.6739502165903136\n"
     ]
    }
   ],
   "source": [
    "afam_rmse = np.sqrt(np.sum((fi_all.fi_base - fi_all.fi_afam)**2))\n",
    "white_rmse = np.sqrt(np.sum((fi_all.fi_base - fi_all.fi_white)**2))\n",
    "print(afam_rmse, white_rmse)\n",
    "afam_rmse_rank = np.sqrt(np.sum((fi_all.fi_base_rank - fi_all.fi_afam_rank)**2))\n",
    "white_rmse_rank = np.sqrt(np.sum((fi_all.fi_base_rank - fi_all.fi_white_rank)**2))\n",
    "print(afam_rmse_rank/fi_all.shape[0], white_rmse_rank/fi_all.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_base_2 = pd.read_csv(\"D:\\\\Yifeng -- Project Work\\\\ys8mz_sandbox\\\\bias_analyses_3h\\\\fi_base.csv\")\n",
    "fi_base_2 = fi_base_2.rename(columns = {'fi':'fi_base'})\n",
    "fi_afam_2 = pd.read_csv(\"D:\\\\Yifeng -- Project Work\\\\ys8mz_sandbox\\\\bias_analyses_3h\\\\fi_afam.csv\")\n",
    "fi_afam_2 = fi_afam_2.rename(columns = {'fi':'fi_afam'})\n",
    "fi_white_2 = pd.read_csv(\"D:\\\\Yifeng -- Project Work\\\\ys8mz_sandbox\\\\bias_analyses_3h\\\\fi_white.csv\")\n",
    "fi_white_2 = fi_white_2.rename(columns = {'fi':'fi_white'})\n",
    "fi_all_2 = fi_base_2.merge(fi_afam_2, on=['predictor'], how='inner').merge(fi_white_2, on=['predictor'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "for p in ['fi_base', 'fi_afam', 'fi_white']:\n",
    "    fi_all_2.loc[:, p+\"_rank\"] = rankdata(fi_all_2[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013336820972155604 0.006247435684610987\n",
      "0.8026433379149043 0.4425616263926167\n"
     ]
    }
   ],
   "source": [
    "afam_rmse_2 = np.sqrt(np.sum((fi_all_2.fi_base - fi_all_2.fi_afam)**2))\n",
    "white_rmse_2 = np.sqrt(np.sum((fi_all_2.fi_base - fi_all_2.fi_white)**2))\n",
    "print(afam_rmse_2, white_rmse_2)\n",
    "afam_rmse_2_rank = np.sqrt(np.sum((fi_all_2.fi_base_rank - fi_all_2.fi_afam_rank)**2))\n",
    "white_rmse_2_rank = np.sqrt(np.sum((fi_all_2.fi_base_rank - fi_all_2.fi_white_rank)**2))\n",
    "print(afam_rmse_2_rank/fi_all_2.shape[0], white_rmse_2_rank/fi_all_2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crnt_enrl_intensity',\n",
       " 'cum_gpa',\n",
       " 'avg_g',\n",
       " 'term_gpa_1',\n",
       " 'past_avg_grade',\n",
       " 'avg_g_concurrent',\n",
       " 'median_income_households',\n",
       " 'perc_below_pov',\n",
       " 'overall_prop_comp',\n",
       " 'section_size',\n",
       " 'distance',\n",
       " 'age',\n",
       " 'term_gpa_2',\n",
       " 'first_strm',\n",
       " 'cum_cred_earn',\n",
       " 'gpa_trend',\n",
       " 'prop_comp_sd',\n",
       " 'pct_withdrawn',\n",
       " 'lvl2_share',\n",
       " 'enrl_intensity',\n",
       " 'enrl_intensity_trend',\n",
       " 'online_share',\n",
       " 'pct_stopped',\n",
       " 'pct_dev',\n",
       " 'eve_share',\n",
       " 'num_of_prior_terms',\n",
       " 'online_ind',\n",
       " 'full_time',\n",
       " 'tenure',\n",
       " 'SOC_SOC_grade',\n",
       " 'HUM_SOC_grade',\n",
       " 'male',\n",
       " 'HUM_HUM_grade',\n",
       " 'pct_incomplete',\n",
       " 'firstgen_0',\n",
       " 'pell_ever_0',\n",
       " 'pell_target_1',\n",
       " 'summer_ind',\n",
       " 'lvl2_ind',\n",
       " 'firstgen_1',\n",
       " 'HUM_MTH_grade',\n",
       " 'degree_level_1',\n",
       " 'SOC_HUM_grade',\n",
       " 'cip_24',\n",
       " 'college_NVCC',\n",
       " 'dev',\n",
       " 'prereq_grade',\n",
       " 'repeat_grade',\n",
       " 'MTH_SOC_grade',\n",
       " 'HUM_MED_grade',\n",
       " 'college_TCC',\n",
       " 'MTH_HUM_grade',\n",
       " 'pell_target_0',\n",
       " 'ever_dual',\n",
       " 'degree_level_2',\n",
       " 'SCI_SOC_grade',\n",
       " 'HUM_SCI_grade',\n",
       " 'eve_ind',\n",
       " 'cip_52',\n",
       " 'SOC_MED_grade',\n",
       " 'MTH_MTH_grade',\n",
       " 'MED_MED_grade',\n",
       " 'SCI_MED_grade',\n",
       " 'pell_ever_1',\n",
       " 'HUM_EGR_grade',\n",
       " 'SOC_MTH_grade',\n",
       " 'EGR_SOC_grade',\n",
       " 'EGR_HUM_grade',\n",
       " 'MED_SOC_grade',\n",
       " 'SCI_HUM_grade',\n",
       " 'SOC_SCI_grade',\n",
       " 'EGR_EGR_grade',\n",
       " 'cip_30',\n",
       " 'MTH_SCI_grade',\n",
       " 'cip_51',\n",
       " 'cip_45',\n",
       " 'MED_HUM_grade',\n",
       " 'MTH_MED_grade',\n",
       " 'SCI_SCI_grade',\n",
       " 'degree_level_3',\n",
       " 'MTH_EGR_grade',\n",
       " 'college_JSRCC',\n",
       " 'SOC_EGR_grade',\n",
       " 'cip_11',\n",
       " 'EGR_MTH_grade',\n",
       " 'college_JTCC',\n",
       " 'college_TNCC',\n",
       " 'SCI_MTH_grade',\n",
       " 'HUM_BUS_grade',\n",
       " 'college_GCC',\n",
       " 'MED_SCI_grade',\n",
       " 'EGR_SCI_grade',\n",
       " 'EGR_MED_grade',\n",
       " 'college_VWCC',\n",
       " 'cip_14',\n",
       " 'BUS_SOC_grade',\n",
       " 'college_LFCC',\n",
       " 'BUS_HUM_grade',\n",
       " 'BUS_BUS_grade',\n",
       " 'SOC_BUS_grade',\n",
       " 'SCI_EGR_grade',\n",
       " 'MED_EGR_grade',\n",
       " 'MED_MTH_grade',\n",
       " 'MTH_BUS_grade',\n",
       " 'ART_SOC_grade',\n",
       " 'HUM_ART_grade',\n",
       " 'OCC_OCC_grade',\n",
       " 'ART_HUM_grade',\n",
       " 'FLA_HUM_grade',\n",
       " 'cip_43',\n",
       " 'EGR_BUS_grade',\n",
       " 'college_PVCC',\n",
       " 'college_NRCC',\n",
       " 'college_CVCC',\n",
       " 'FLA_SOC_grade',\n",
       " 'cip_50',\n",
       " 'SOC_ART_grade',\n",
       " 'BUS_EGR_grade',\n",
       " 'cip_15',\n",
       " 'MTH_ART_grade',\n",
       " 'MED_BUS_grade',\n",
       " 'BUS_MTH_grade',\n",
       " 'college_SWVCC',\n",
       " 'college_SSVCC',\n",
       " 'ART_SCI_grade',\n",
       " 'HUM_OCC_grade',\n",
       " 'SCI_BUS_grade',\n",
       " 'ART_MTH_grade',\n",
       " 'cip_47',\n",
       " 'ART_EGR_grade',\n",
       " 'college_DCC',\n",
       " 'college_PHCC',\n",
       " 'cip_99',\n",
       " 'college_VHCC',\n",
       " 'ART_ART_grade',\n",
       " 'BUS_SCI_grade',\n",
       " 'college_MECC',\n",
       " 'cip_19',\n",
       " 'college_RCC',\n",
       " 'FLA_MTH_grade',\n",
       " 'EGR_ART_grade',\n",
       " 'college_WCC',\n",
       " 'FLA_SCI_grade',\n",
       " 'HUM_FLA_grade',\n",
       " 'OCC_HUM_grade',\n",
       " 'MED_ART_grade',\n",
       " 'SCI_ART_grade',\n",
       " 'ART_MED_grade',\n",
       " 'FLA_EGR_grade',\n",
       " 'BUS_MED_grade',\n",
       " 'SOC_FLA_grade',\n",
       " 'first_ind',\n",
       " 'MTH_OCC_grade',\n",
       " 'OCC_EGR_grade',\n",
       " 'OCC_SOC_grade',\n",
       " 'MTH_FLA_grade',\n",
       " 'ART_BUS_grade',\n",
       " 'EGR_OCC_grade',\n",
       " 'FLA_MED_grade',\n",
       " 'SOC_OCC_grade',\n",
       " 'cip_12',\n",
       " 'college_PDCCC',\n",
       " 'cip_48',\n",
       " 'cip_22',\n",
       " 'college_DSLCC',\n",
       " 'FLA_FLA_grade',\n",
       " 'BUS_ART_grade',\n",
       " 'SCI_FLA_grade',\n",
       " 'FLA_BUS_grade',\n",
       " 'MED_FLA_grade',\n",
       " 'MED_OCC_grade',\n",
       " 'EGR_FLA_grade',\n",
       " 'OCC_MTH_grade',\n",
       " 'OCC_MED_grade',\n",
       " 'college_ESCC',\n",
       " 'SCI_OCC_grade',\n",
       " 'OCC_SCI_grade',\n",
       " 'FLA_ART_grade',\n",
       " 'ART_FLA_grade',\n",
       " 'OCC_BUS_grade',\n",
       " 'BUS_OCC_grade',\n",
       " 'BUS_FLA_grade',\n",
       " 'ART_OCC_grade',\n",
       " 'OCC_ART_grade',\n",
       " 'FLA_OCC_grade',\n",
       " 'OCC_FLA_grade']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fi_all_2.predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx = np.array(predictors)[np.argsort(rf.feature_importances_)[::-1]]\n",
    "yy = rf.feature_importances_[np.argsort(rf.feature_importances_)[::-1]]\n",
    "top10 = list(pd.DataFrame({'predictor':xx, 'fi':yy}).iloc[:10,:].predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('term_cred_att_sp1', 0.02123789629262577)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx[10], yy[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'predictor':xx, 'fi':yy}).iloc[:10,:].to_csv(\"top10_predictors_without_race.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10_predictors = list(pd.DataFrame({'predictor':xx, 'fi':yy}).iloc[:10,:].predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_stata(\"degree_completion_full_sample_orig_RF.dta\")\n",
    "df2 = df2.merge(test_df.loc[:,['vccsid','white','afam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prop_comp_sp1', 'term_gpa_fa1', 'term_gpa_sp1', 'prop_comp_fa1']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_new = [p for p in top10 if p.endswith(\"1\")]\n",
    "top10_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import CompareMeans,DescrStatsW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for pp in top10_predictors:\n",
    "    if pp in top10_new:\n",
    "        p = pp + \"_orig\"\n",
    "    else:\n",
    "        p = pp\n",
    "    x = np.array(df2.loc[:,p])\n",
    "    white_indices = np.where(df2.white == 1)[0]\n",
    "    nonwhite_indices = np.where(df2['afam'] == 1)[0]\n",
    "    x_1 = x[white_indices]\n",
    "    x_1 = x_1[~pd.isnull(x_1)]\n",
    "    x_2 = x[nonwhite_indices]\n",
    "    x_2 = x_2[~pd.isnull(x_2)]\n",
    "    test_result = CompareMeans(DescrStatsW(x_1), DescrStatsW(x_2)).ztest_ind(alternative='two-sided', usevar='unequal')\n",
    "    p_vals = str(test_result[1]).split(\"e\")\n",
    "    if len(p_vals) == 1:\n",
    "        new_p_val = str(round(float(p_vals[0]),4))\n",
    "    else:\n",
    "        new_p_val = str(round(float(p_vals[0]),4)) + \"e\" + p_vals[1]\n",
    "    white_mean = round(np.mean(x_1), 4)\n",
    "    diff_in_mean = round(np.mean(x_2) - np.mean(x_1),4)\n",
    "    if pp in top10_new:\n",
    "        x_1 = x[white_indices]\n",
    "        x_1 = pd.isnull(x_1).astype(int)\n",
    "        x_2 = x[nonwhite_indices]\n",
    "        x_2 = pd.isnull(x_2).astype(int)\n",
    "        test_result = CompareMeans(DescrStatsW(x_1), DescrStatsW(x_2)).ztest_ind(alternative='two-sided', usevar='unequal')\n",
    "        p_vals = str(test_result[1]).split(\"e\")\n",
    "        if len(p_vals) == 1:\n",
    "            new_p_val_2 = str(round(float(p_vals[0]),4))\n",
    "        else:\n",
    "            new_p_val_2 = str(round(float(p_vals[0]),4)) + \"e\" + p_vals[1]\n",
    "        white_mean_2 = round(np.mean(x_1), 4)\n",
    "        diff_in_mean_2 = round(np.mean(x_2) - np.mean(x_1),4)\n",
    "        rows.append((pp, white_mean, diff_in_mean, new_p_val, white_mean_2, diff_in_mean_2, new_p_val_2))\n",
    "    else:\n",
    "        rows.append((pp, white_mean, diff_in_mean, new_p_val))\n",
    "table = pd.DataFrame(rows[:], columns=['predictor', \"white_mean\", 'diff_in_mean', 'p_value', 'white_mi_perc', 'diff_in_mi_perc', 'p_value_mi'])\n",
    "table.loc[:,'p_value'] = table.p_value.astype(float).round(4)\n",
    "table.loc[:,'p_value_mi'] = table.p_value_mi.astype(float).round(4)\n",
    "table.round(4).to_csv(\"key_predictor_difference_{}.csv\".format('afam'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
