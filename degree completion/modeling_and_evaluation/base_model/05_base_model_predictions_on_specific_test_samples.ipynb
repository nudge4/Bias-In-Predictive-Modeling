{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script uses the base model to generate the predicted scores on XX-specific (e.g. college-specific, first-term-specific) samples. Those XX-specific scores will be used in subsequent steps of comparing algorithmic biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats.mstats import gmean\n",
    "import math\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "font = {'size': 24}\n",
    "matplotlib.rc('font', **font)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "\n",
    "df_new = pd.read_stata(\"full_data_truncated_enlarged_new.dta\")\n",
    "predictors = pickle.load(open(\"predictors_rf2.p\", \"rb\"))\n",
    "\n",
    "\n",
    "l1 = ['coll_lvl_cred_earn', 'prop_comp_pre', 'cum_gpa_pre']\n",
    "for p in l1:\n",
    "    v = np.min(df_new[p]) - 1\n",
    "    df_new.loc[:, p] = df_new.apply(lambda x: v if x['enrolled_pre'] != 1 else x[p], axis=1)\n",
    "l2 = ['admrate', 'gradrate', 'satvr25', 'satvr75', 'satmt25', 'satmt75', 'satwr25', 'satwr75', 'nsc_coll_type_1', 'nsc_coll_type_2', 'nsc_coll_type_3', 'nsc_coll_type_4', 'nsc_coll_type_5', 'nsc_coll_type_6', 'nsc_coll_type_7', 'nsc_coll_type_8']\n",
    "for p in l2:\n",
    "    v = np.min(df_new[p]) - 1\n",
    "    df_new.loc[:, p] = df_new.apply(lambda x: v if x['enrolled_nsc'] != 1 else x[p], axis=1)\n",
    "l3 = ['degree_seeking', 'term_cred_att', 'term_gpa', 'prop_comp', 'withdrawn_prop_comp', 'lvl2_prop_comp', 'dev_prop_comp', 'repeat']\n",
    "for t in ['su', 'fa', 'sp']:\n",
    "    for i in range(1,7):\n",
    "        for pp in l3:\n",
    "            p = pp + \"_\" + t + str(i)\n",
    "            v = np.min(df_new[p]) - 1\n",
    "            df_new.loc[:, p] = df_new.apply(lambda x: v if x['enrolled_' + t + str(i)] != 1 else x[p], axis=1)\n",
    "l4 = ['enrl_intensity_nsc']\n",
    "for t in ['su', 'fa', 'sp']:\n",
    "    for i in range(1,7):\n",
    "        for pp in l4:\n",
    "            p = pp + \"_\" + t + str(i)\n",
    "            v = np.min(df_new[p]) - 1\n",
    "            df_new.loc[:, p] = df_new.apply(lambda x: v if x['enrolled_nsc_' + t + str(i)] != 1 else x[p], axis=1)\n",
    "l5 = ['grants', 'sub_loans', 'unsub_loans', 'others']\n",
    "for i in range(1,7):\n",
    "    for pp in l5:\n",
    "        p = pp + \"_yr\" + str(i)\n",
    "        v = np.min(df_new[p]) - 1\n",
    "        df_new.loc[:, p] = df_new.apply(lambda x: v if x['enrolled_yr' + str(i)] != 1 else x[p], axis=1)\n",
    "to_drop = ['enrolled_pre', 'enrolled_nsc'] + ['enrolled_' + t + str(i) for t in ['su', 'fa', 'sp'] for i in range(1,7)] + ['enrolled_nsc_' + t + str(i) for t in ['su', 'fa', 'sp'] for i in range(1,7)]\n",
    "predictors = [p for p in predictors if p not in set(to_drop)]\n",
    "print(len(predictors))\n",
    "\n",
    "train_df = df_new[df_new.valid == 0]\n",
    "test_df = df_new[df_new.valid == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new.to_stata(\"df_new.dta\", write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(predictors, open(\"predictors.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True,\n",
       "            class_weight={0.0: 1.0, 1.0: 1.3931639}, criterion='entropy',\n",
       "            max_depth=16, max_features=12, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=120, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_d = 16\n",
    "optimal_n = 120\n",
    "optimal_nf = 12\n",
    "rf = RandomForestClassifier(n_estimators=optimal_n, criterion=\"entropy\",\n",
    "                            max_depth=optimal_d,\n",
    "                            random_state=0, n_jobs=-1, max_features=optimal_nf,\n",
    "                            class_weight = calc_cw(train_df.grad_6years))\n",
    "rf.fit(train_df.loc[:,predictors], train_df.grad_6years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### first-term-specific and returning-specific\n",
    "first_ind = pd.read_stata(\"../degree_completion_1/full_data_truncated_enlarged_new.dta\")\n",
    "first_ind.loc[:,'available_sum'] = 0\n",
    "for p in [p for p in list(first_ind.columns)[10:] if p.startswith(\"available\") and p != \"available_sum\"]:\n",
    "    first_ind.loc[:,'available_sum'] += first_ind[p]\n",
    "first_ind.loc[:,'first_ind'] = first_ind.available_sum.apply(lambda x: x <= 1).astype(int)\n",
    "first_ind = first_ind.loc[:,['vccsid', 'first_ind']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Validation AUC = 0.8935\n",
      "47371 47371 47371\n",
      "Random Forest:\n",
      "Validation AUC = 0.8781\n",
      "14678 14678 14678\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.read_stata(\"df_new.dta\")\n",
    "df_new = df_new.merge(first_ind, on=['vccsid'], how='left')\n",
    "test_df_all = df_new[df_new.valid == 1]\n",
    "for r in [0,1]:\n",
    "    test_df = test_df_all[test_df_all.first_ind == r]\n",
    "    y_test_pred_rf = rf.predict_proba(test_df.loc[:,predictors])[:,1]\n",
    "    print(\"Random Forest:\")\n",
    "    print(\"Validation AUC = {}\".format(round(roc_auc_score(test_df.grad_6years, y_test_pred_rf),4)))\n",
    "\n",
    "    race_column = []\n",
    "    for i in range(test_df.shape[0]):\n",
    "        if test_df.white.iloc[i] == 1:\n",
    "            race_column.append(\"white\")\n",
    "        elif test_df.afam.iloc[i] == 1:\n",
    "            race_column.append(\"afam\")\n",
    "        elif test_df.hisp.iloc[i] == 1:\n",
    "            race_column.append(\"hisp\")\n",
    "        elif test_df.asian.iloc[i] == 1:\n",
    "            race_column.append(\"asian\")\n",
    "        elif test_df.other.iloc[i] == 1:\n",
    "            race_column.append(\"other\")\n",
    "        else:\n",
    "            race_column.append(\"mi\")\n",
    "    race_column = np.array(race_column)\n",
    "    pred_y = np.array(y_test_pred_rf)\n",
    "    test_y = np.array(test_df.grad_6years)\n",
    "    pred_y = pred_y[race_column != \"mi\"]\n",
    "    test_y = test_y[race_column != \"mi\"]\n",
    "    race_column = race_column[race_column != \"mi\"]\n",
    "    print(len(race_column), len(pred_y), len(test_y))\n",
    "\n",
    "    pred_score_by_race = pd.DataFrame({'race_column': race_column, 'pred_y': pred_y, 'test_y': test_y})\n",
    "    pred_score_by_race.to_csv(\"../degree_completion_5/full/pred_score_by_race_{}.csv\".format(r), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Validation AUC = 0.9059\n",
      "35978 35978 35978\n",
      "Random Forest:\n",
      "Validation AUC = 0.9064\n",
      "13985 13985 13985\n",
      "Random Forest:\n",
      "Validation AUC = 0.896\n",
      "2822 2822 2822\n",
      "Random Forest:\n",
      "Validation AUC = 0.85\n",
      "5390 5390 5390\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.read_stata(\"df_new.dta\")\n",
    "program = pd.read_stata(\"../degree_completion_9/student_deglvl.dta\")\n",
    "df_new = program.merge(df_new, on=['vccsid'], how='right')\n",
    "test_df_all = df_new[df_new.valid == 1]\n",
    "for r in ['AA&S', 'AAS', 'CERT', 'CSC']:\n",
    "    test_df = test_df_all[test_df_all.deglvl == r]\n",
    "    y_test_pred_rf = rf.predict_proba(test_df.loc[:,predictors])[:,1]\n",
    "    print(\"Random Forest:\")\n",
    "    print(\"Validation AUC = {}\".format(round(roc_auc_score(test_df.grad_6years, y_test_pred_rf),4)))\n",
    "\n",
    "    race_column = []\n",
    "    for i in range(test_df.shape[0]):\n",
    "        if test_df.white.iloc[i] == 1:\n",
    "            race_column.append(\"white\")\n",
    "        elif test_df.afam.iloc[i] == 1:\n",
    "            race_column.append(\"afam\")\n",
    "        elif test_df.hisp.iloc[i] == 1:\n",
    "            race_column.append(\"hisp\")\n",
    "        elif test_df.asian.iloc[i] == 1:\n",
    "            race_column.append(\"asian\")\n",
    "        elif test_df.other.iloc[i] == 1:\n",
    "            race_column.append(\"other\")\n",
    "        else:\n",
    "            race_column.append(\"mi\")\n",
    "    race_column = np.array(race_column)\n",
    "    pred_y = np.array(y_test_pred_rf)\n",
    "    test_y = np.array(test_df.grad_6years)\n",
    "    pred_y = pred_y[race_column != \"mi\"]\n",
    "    test_y = test_y[race_column != \"mi\"]\n",
    "    race_column = race_column[race_column != \"mi\"]\n",
    "    print(len(race_column), len(pred_y), len(test_y))\n",
    "\n",
    "    pred_score_by_race = pd.DataFrame({'race_column': race_column, 'pred_y': pred_y, 'test_y': test_y})\n",
    "    pred_score_by_race.to_csv(\"../degree_completion_9/full/pred_score_by_race_{}.csv\".format(r), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Validation AUC = 0.8891\n",
      "7222 7222 7222\n",
      "Random Forest:\n",
      "Validation AUC = 0.9046\n",
      "5030 5030 5030\n",
      "Random Forest:\n",
      "Validation AUC = 0.8885\n",
      "4229 4229 4229\n",
      "Random Forest:\n",
      "Validation AUC = 0.9109\n",
      "4557 4557 4557\n",
      "Random Forest:\n",
      "Validation AUC = 0.9284\n",
      "3963 3963 3963\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.read_stata(\"df_new.dta\")\n",
    "program = pd.read_csv(\"../degree_completion_6/college_program_race.csv\")\n",
    "program.loc[:,'curr_degree_lvl'] = program.curr.astype(str) + \"_\" + program.degree_lvl\n",
    "program = program.loc[:,['vccsid', 'curr_degree_lvl']]\n",
    "df_new = program.merge(df_new, on=['vccsid'], how='right')\n",
    "df_new = df_new[df_new.curr_degree_lvl.apply(lambda x: x in {\"213_A\", \"697_A\", \"699_A\", \"880_A\", \"882_A\"})]\n",
    "df_new.loc[:,'curr_degree_lvl'] = df_new.curr_degree_lvl.apply(lambda x: x[:3])\n",
    "df_new = df_new.rename(columns = {'curr_degree_lvl': 'curr'})\n",
    "test_df_all = df_new[df_new.valid == 1]\n",
    "for r in ['699', '213', '880', '882', '697']:\n",
    "    test_df = test_df_all[test_df_all.curr == r]\n",
    "    y_test_pred_rf = rf.predict_proba(test_df.loc[:,predictors])[:,1]\n",
    "    print(\"Random Forest:\")\n",
    "    print(\"Validation AUC = {}\".format(round(roc_auc_score(test_df.grad_6years, y_test_pred_rf),4)))\n",
    "\n",
    "    race_column = []\n",
    "    for i in range(test_df.shape[0]):\n",
    "        if test_df.white.iloc[i] == 1:\n",
    "            race_column.append(\"white\")\n",
    "        elif test_df.afam.iloc[i] == 1:\n",
    "            race_column.append(\"afam\")\n",
    "        elif test_df.hisp.iloc[i] == 1:\n",
    "            race_column.append(\"hisp\")\n",
    "        elif test_df.asian.iloc[i] == 1:\n",
    "            race_column.append(\"asian\")\n",
    "        elif test_df.other.iloc[i] == 1:\n",
    "            race_column.append(\"other\")\n",
    "        else:\n",
    "            race_column.append(\"mi\")\n",
    "    race_column = np.array(race_column)\n",
    "    pred_y = np.array(y_test_pred_rf)\n",
    "    test_y = np.array(test_df.grad_6years)\n",
    "    pred_y = pred_y[race_column != \"mi\"]\n",
    "    test_y = test_y[race_column != \"mi\"]\n",
    "    race_column = race_column[race_column != \"mi\"]\n",
    "    print(len(race_column), len(pred_y), len(test_y))\n",
    "\n",
    "    pred_score_by_race = pd.DataFrame({'race_column': race_column, 'pred_y': pred_y, 'test_y': test_y})\n",
    "    pred_score_by_race.to_csv(\"../degree_completion_6/full/pred_score_by_race_{}.csv\".format(r), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J._Sargeant_Reynolds\n",
      "Random Forest:\n",
      "Validation AUC = 0.9079\n",
      "4248 4248 4248\n",
      "John_Tyler\n",
      "Random Forest:\n",
      "Validation AUC = 0.8992\n",
      "2839 2839 2839\n",
      "Northern_Virginia\n",
      "Random Forest:\n",
      "Validation AUC = 0.8978\n",
      "18246 18246 18246\n",
      "Tidewater\n",
      "Random Forest:\n",
      "Validation AUC = 0.8749\n",
      "11489 11489 11489\n",
      "Thomas_Nelson\n",
      "Random Forest:\n",
      "Validation AUC = 0.8705\n",
      "4120 4120 4120\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.read_stata(\"df_new.dta\")\n",
    "program = pd.read_csv(\"../degree_completion_6/college_program_race.csv\")\n",
    "program = program.loc[:,['vccsid', 'college']]\n",
    "df_new = program.merge(df_new, on=['vccsid'], how='right')\n",
    "test_df_all = df_new[df_new.valid == 1]\n",
    "\n",
    "params_dict = {'JSRCC': [12, 120, 10],\n",
    "               'JTCC': [12, 120, 8],\n",
    "               'NVCC': [14, 120, 10],\n",
    "               'TCC': [13, 120, 13],\n",
    "               'TNCC': [12, 160, 9]}\n",
    "cname = {'Northern_Virginia': \"NVCC\", \"Tidewater\": \"TCC\", \"J._Sargeant_Reynolds\": \"JSRCC\", \"Thomas_Nelson\": \"TNCC\", \"John_Tyler\": \"JTCC\"}\n",
    "for r2 in ['J._Sargeant_Reynolds', 'John_Tyler', 'Northern_Virginia', 'Tidewater', 'Thomas_Nelson']:\n",
    "    # Load the training/validation sample\n",
    "    print(r2)\n",
    "    r = cname[r2]\n",
    "    test_df = test_df_all[test_df_all.college == r2]\n",
    "    y_test_pred_rf = rf.predict_proba(test_df.loc[:,predictors])[:,1]\n",
    "    print(\"Random Forest:\")\n",
    "    print(\"Validation AUC = {}\".format(round(roc_auc_score(test_df.grad_6years, y_test_pred_rf),4)))\n",
    "    \n",
    "    race_column = []\n",
    "    for i in range(test_df.shape[0]):\n",
    "        if test_df.white.iloc[i] == 1:\n",
    "            race_column.append(\"white\")\n",
    "        elif test_df.afam.iloc[i] == 1:\n",
    "            race_column.append(\"afam\")\n",
    "        elif test_df.hisp.iloc[i] == 1:\n",
    "            race_column.append(\"hisp\")\n",
    "        elif test_df.asian.iloc[i] == 1:\n",
    "            race_column.append(\"asian\")\n",
    "        elif test_df.other.iloc[i] == 1:\n",
    "            race_column.append(\"other\")\n",
    "        else:\n",
    "            race_column.append(\"mi\")\n",
    "    race_column = np.array(race_column)\n",
    "    pred_y = np.array(y_test_pred_rf)\n",
    "    test_y = np.array(test_df.grad_6years)\n",
    "    pred_y = pred_y[race_column != \"mi\"]\n",
    "    test_y = test_y[race_column != \"mi\"]\n",
    "    race_column = race_column[race_column != \"mi\"]\n",
    "    print(len(race_column), len(pred_y), len(test_y))\n",
    "\n",
    "    pred_score_by_race = pd.DataFrame({'race_column': race_column, 'pred_y': pred_y, 'test_y': test_y})\n",
    "    pred_score_by_race.to_csv(\"../degree_completion_7/full/pred_score_by_race_{}.csv\".format(r), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
