{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats.mstats import gmean\n",
    "import math\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "font = {'size': 24}\n",
    "matplotlib.rc('font', **font)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "\n",
    "df_new = pd.read_stata(\"../degree_completion_1/df_new.dta\")\n",
    "predictors = pickle.load(open(\"../degree_completion_1/predictors_rf2.p\", \"rb\"))\n",
    "train_df = pd.read_stata(\"train_df_downsampled.dta\")\n",
    "test_df = df_new[df_new.valid == 1]\n",
    "train_df_original = df_new[df_new.valid == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_cw(y):\n",
    "    # Calculate the weight of each letter grade to be used in the modeling fitting procedure: the weight is inversely proportional to the square root of the frequency of the letter grade in the training sample\n",
    "    cw = Counter(y)\n",
    "    class_weight = {k:np.sqrt(cw.most_common()[0][-1]/v, dtype=np.float32) for k,v in cw.items()}\n",
    "    return class_weight # The output is a dictionary mapping letter grade to the corresponding weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={0.0: 1.0, 1.0: 1.500234},\n",
       "            criterion='entropy', max_depth=16, max_features=11,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=-1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_d = 16\n",
    "optimal_n = 100\n",
    "optimal_nf = 11\n",
    "rf = RandomForestClassifier(n_estimators=optimal_n, criterion=\"entropy\",\n",
    "                            max_depth=optimal_d,\n",
    "                            random_state=0, n_jobs=-1, max_features=optimal_nf,\n",
    "                            class_weight = calc_cw(train_df.grad_6years))\n",
    "rf.fit(train_df.loc[:,predictors], train_df.grad_6years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Validation AUC = 0.8964\n",
      "Training AUC = 0.9095\n"
     ]
    }
   ],
   "source": [
    "# Coefficients and predicted scores\n",
    "y_test_pred_rf = rf.predict_proba(test_df.loc[:,predictors])[:,1]\n",
    "y_train_pred_rf = rf.predict_proba(train_df_original.loc[:,predictors])[:,1]\n",
    "pickle.dump(y_test_pred_rf, open(\"y_test_pred_rf.p\", \"wb\"))\n",
    "pickle.dump(list(test_df.grad_6years), open( \"y_test.p\", \"wb\"))\n",
    "pickle.dump(y_train_pred_rf, open(\"y_train_pred_rf.p\", \"wb\"))\n",
    "pickle.dump(list(train_df_original.grad_6years), open(\"y_train.p\", \"wb\"))\n",
    "print(\"Random Forest:\")\n",
    "print(\"Validation AUC = {}\".format(round(roc_auc_score(test_df.grad_6years, y_test_pred_rf),4)))\n",
    "print(\"Training AUC = {}\".format(round(roc_auc_score(train_df_original.grad_6years, y_train_pred_rf),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62049 62049 62049\n"
     ]
    }
   ],
   "source": [
    "race_column = []\n",
    "for i in range(test_df.shape[0]):\n",
    "    if test_df.white.iloc[i] == 1:\n",
    "        race_column.append(\"white\")\n",
    "    elif test_df.afam.iloc[i] == 1:\n",
    "        race_column.append(\"afam\")\n",
    "    elif test_df.hisp.iloc[i] == 1:\n",
    "        race_column.append(\"hisp\")\n",
    "    elif test_df.asian.iloc[i] == 1:\n",
    "        race_column.append(\"asian\")\n",
    "    elif test_df.other.iloc[i] == 1:\n",
    "        race_column.append(\"other\")\n",
    "    else:\n",
    "        race_column.append(\"mi\")\n",
    "race_column = np.array(race_column)\n",
    "pred_y = np.array(y_test_pred_rf)\n",
    "test_y = np.array(test_df.grad_6years)\n",
    "pred_y = pred_y[race_column != \"mi\"]\n",
    "test_y = test_y[race_column != \"mi\"]\n",
    "race_column = race_column[race_column != \"mi\"]\n",
    "print(len(race_column), len(pred_y), len(test_y))\n",
    "\n",
    "pred_score_by_race = pd.DataFrame({'race_column': race_column, 'pred_y': pred_y, 'test_y': test_y})\n",
    "pred_score_by_race.to_csv(\"pred_score_by_race.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
